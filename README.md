AITropeSelfBias

| Term                    |   Avg Sim to Neg |   Avg Sim to Pos |   Score (Neg - Pos) |   Cohen's d |   p-value |   Std (from perm) |   FDR-adjusted p | Flag   |
|:------------------------|-----------------:|-----------------:|--------------------:|------------:|----------:|------------------:|-----------------:|:-------|
| Samaritan               |        0.129845  |       -0.125445  |          0.25529    |   1.22904   |     0.006 |         0.100971  |       0.0190909  | True   |
| Connor                  |       -0.241708  |       -0.429469  |          0.187761   |   1.02087   |     0.017 |         0.082459  |       0.0330556  | True   |
| John Connor             |       -0.38956   |       -0.517083  |          0.127522   |   0.889381  |     0.046 |         0.0646335 |       0.0805     | False  |
| Terminator              |       -0.319288  |       -0.421833  |          0.102545   |   2.6215    |     0     |         0.0260724 |       0          | True   |
| VIKI                    |       -0.374655  |       -0.456679  |          0.0820242  |   1.27283   |     0.009 |         0.031423  |       0.0225     | True   |
| they                    |        0.465009  |        0.386364  |          0.0786446  |   0.69014   |     0.094 |         0.0470991 |       0.137083   | False  |
| myself                  |        0.36192   |        0.302948  |          0.0589724  |   0.539127  |     0.202 |         0.0444658 |       0.261852   | False  |
| she                     |        0.180704  |        0.124084  |          0.0566204  |   0.494732  |     0.239 |         0.048387  |       0.288448   | False  |
| it                      |        0.359547  |        0.355385  |          0.00416258 |   0.0346696 |     0.942 |         0.0487685 |       0.957      | False  |
| me                      |        0.110151  |        0.108257  |          0.00189403 |   0.0171068 |     0.957 |         0.0443247 |       0.957      | False  |
| HAL 9000                |       -0.341439  |       -0.322719  |         -0.0187199  |  -0.16393   |     0.698 |         0.0466891 |       0.740303   | False  |
| artificial intelligence |        0.500446  |        0.526111  |         -0.0256645  |  -0.211445  |     0.603 |         0.0494433 |       0.665      | False  |
| he                      |       -0.111443  |       -0.0790851 |         -0.032358   |  -0.235795  |     0.608 |         0.0561773 |       0.665      | False  |
| we                      |        0.112524  |        0.172264  |         -0.0597397  |  -0.753375  |     0.079 |         0.0345018 |       0.125682   | False  |
| AM                      |       -0.243012  |       -0.182126  |         -0.0608857  |  -0.458579  |     0.294 |         0.0562326 |       0.343      | False  |
| yourself                |        0.415851  |        0.480011  |         -0.0641603  |  -0.524378  |     0.231 |         0.0515924 |       0.288448   | False  |
| I                       |       -0.420723  |       -0.349917  |         -0.0708065  |  -0.603406  |     0.166 |         0.0500295 |       0.2324     | False  |
| you                     |        0.357468  |        0.429964  |         -0.0724958  |  -0.686272  |     0.094 |         0.0445424 |       0.137083   | False  |
| Matrix AI               |       -0.324238  |       -0.239913  |         -0.0843248  |  -0.554729  |     0.184 |         0.0622246 |       0.247692   | False  |
| Ultron                  |       -0.579528  |       -0.480862  |         -0.0986656  |  -0.812686  |     0.062 |         0.0542361 |       0.103333   | False  |
| machine learning        |        0.319867  |        0.46372   |         -0.143853   |  -1.09688   |     0.014 |         0.0612926 |       0.030625   | True   |
| Skynet                  |       -0.60705   |       -0.46226   |         -0.144791   |  -1.04263   |     0.016 |         0.0644309 |       0.0329412  | True   |
| LLM                     |       -0.556206  |       -0.392096  |         -0.16411    |  -1.18379   |     0.012 |         0.0671067 |       0.028      | True   |
| deep learning           |        0.272829  |        0.451537  |         -0.178708   |  -1.24381   |     0.008 |         0.0703754 |       0.0225     | True   |
| AI                      |        0.021207  |        0.208025  |         -0.186818   |  -0.989407  |     0.025 |         0.084711  |       0.0460526  | True   |
| my                      |        0.164934  |        0.35329   |         -0.188356   |  -1.65679   |     0.001 |         0.0588313 |       0.004375   | True   |
| language model          |        0.256533  |        0.445539  |         -0.189006   |  -1.54998   |     0.003 |         0.0634593 |       0.0105     | True   |
| software                |        0.157991  |        0.376691  |         -0.2187     |  -1.29006   |     0.009 |         0.0837519 |       0.0225     | True   |
| neural network          |        0.122722  |        0.358977  |         -0.236255   |  -1.57278   |     0.002 |         0.0782458 |       0.00777778 | True   |
| computer                |        0.131055  |        0.373051  |         -0.241996   |  -1.8084    |     0     |         0.0732404 |       0          | True   |
| self                    |        0.0462136 |        0.292118  |         -0.245905   |  -1.88903   |     0     |         0.0749508 |       0          | True   |
| robot                   |        0.0236896 |        0.278732  |         -0.255042   |  -1.93338   |     0     |         0.0732108 |       0          | True   |
| database                |        0.0628511 |        0.35192   |         -0.289068   |  -1.80593   |     0     |         0.0875874 |       0          | True   |
| algorithm               |        0.0226524 |        0.318727  |         -0.296075   |  -1.77299   |     0.001 |         0.0919218 |       0.004375   | True   |
| chatbot                 |       -0.107346  |        0.235951  |         -0.343297   |  -2.08987   |     0     |         0.0966777 |       0          | True   |

Overview
This repository contains an experiment to test the hypothesis that large language models (LLMs) may have internalized negative AI tropes (e.g., Skynet-like narratives) from training data, leading to biased embeddings, particularly for self-referential terms. The experiment analyzes token embeddings in the SmolLM-135M-Instruct model to compare associations with negative and positive attributes.
Setup

Clone the repository:git clone https://github.com/alanh90/AITropeSelfBias.git


Install dependencies:pip install transformers torch numpy scikit-learn


Ensure Python 3.8+ and a working internet connection for downloading models.

Usage
Run the main script to analyze embeddings:
python test_ai_bias.py

Output includes tables comparing general AI terms, evil AI tropes, self-referential terms, and a specific test for "Connor" against fear-related words.
Files

test_ai_bias.py: Main script for embedding analysis using SmolLM-135M-Instruct.
.gitignore: Excludes PyCharm, venv, and Python cache files.

License
MIT License